{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daoudecho/Introduction-to-TensorFlow/blob/master/Copy_of_Exercise_7_Question_horse_human.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "a467202b-b353-4efa-827b-b99b5b13bdf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-16 13:11:00--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  51.2MB/s    in 1.6s    \n",
            "\n",
            "2019-09-16 13:11:02 (51.2 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "cdbec0b4-18c3-4bca-b175-20cb16efdd63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "9d9bd4a0-7576-40b1-dc16-02bc6d79102d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(  pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics =['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "55dedcf3-767f-4fc3-a5a5-b76fd13cd00a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-16 13:11:17--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  29.6MB/s    in 4.8s    \n",
            "\n",
            "2019-09-16 13:11:24 (29.6 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-09-16 13:11:26--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  27.3MB/s    in 0.4s    \n",
            "\n",
            "2019-09-16 13:11:27 (27.3 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "4af4aa6a-3d9c-481f-c3c2-df6f637b6e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "\n",
        "\n",
        "train_horses_dir =  os.path.join(train_dir, 'horses')\n",
        "train_humans_dir = os.path.join(train_dir, 'humans')\n",
        "validation_horses_dir =os.path.join(validation_dir, 'horses')\n",
        "validation_humans_dir =os.path.join(validation_dir, 'humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "4cca46a6-087e-4ca4-8591-69215f0e4787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "3b7ecfb9-87bc-4bd8-a328-13a682087939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 - 36s - loss: 0.1733 - acc: 0.9326 - val_loss: 0.0270 - val_acc: 0.9899\n",
            "Epoch 2/100\n",
            "100/100 - 30s - loss: 0.0733 - acc: 0.9750 - val_loss: 4.7374e-04 - val_acc: 1.0000\n",
            "Epoch 3/100\n",
            "100/100 - 29s - loss: 0.0471 - acc: 0.9829 - val_loss: 0.0196 - val_acc: 0.9960\n",
            "Epoch 4/100\n",
            "100/100 - 29s - loss: 0.0583 - acc: 0.9801 - val_loss: 0.0328 - val_acc: 0.9929\n",
            "Epoch 5/100\n",
            "100/100 - 29s - loss: 0.0301 - acc: 0.9883 - val_loss: 0.0028 - val_acc: 1.0000\n",
            "Epoch 6/100\n",
            "100/100 - 29s - loss: 0.0322 - acc: 0.9919 - val_loss: 0.0357 - val_acc: 0.9960\n",
            "Epoch 7/100\n",
            "100/100 - 29s - loss: 0.0387 - acc: 0.9869 - val_loss: 0.0410 - val_acc: 0.9960\n",
            "Epoch 8/100\n",
            "100/100 - 29s - loss: 0.0223 - acc: 0.9924 - val_loss: 0.1340 - val_acc: 0.9757\n",
            "Epoch 9/100\n",
            "100/100 - 29s - loss: 0.0359 - acc: 0.9894 - val_loss: 0.1854 - val_acc: 0.9727\n",
            "Epoch 10/100\n",
            "100/100 - 28s - loss: 0.0355 - acc: 0.9883 - val_loss: 0.1016 - val_acc: 0.9838\n",
            "Epoch 11/100\n",
            "100/100 - 29s - loss: 0.0244 - acc: 0.9919 - val_loss: 0.4596 - val_acc: 0.9575\n",
            "Epoch 12/100\n",
            "100/100 - 28s - loss: 0.0388 - acc: 0.9868 - val_loss: 0.2833 - val_acc: 0.9636\n",
            "Epoch 13/100\n",
            "100/100 - 29s - loss: 0.0272 - acc: 0.9939 - val_loss: 0.7073 - val_acc: 0.9545\n",
            "Epoch 14/100\n",
            "100/100 - 28s - loss: 0.0329 - acc: 0.9889 - val_loss: 0.3401 - val_acc: 0.9605\n",
            "Epoch 15/100\n",
            "100/100 - 30s - loss: 0.0349 - acc: 0.9919 - val_loss: 0.2997 - val_acc: 0.9737\n",
            "Epoch 16/100\n",
            "100/100 - 30s - loss: 0.0193 - acc: 0.9944 - val_loss: 0.3314 - val_acc: 0.9676\n",
            "Epoch 17/100\n",
            "100/100 - 29s - loss: 0.0161 - acc: 0.9949 - val_loss: 0.4822 - val_acc: 0.9605\n",
            "Epoch 18/100\n",
            "100/100 - 29s - loss: 0.0512 - acc: 0.9868 - val_loss: 0.6613 - val_acc: 0.9636\n",
            "Epoch 19/100\n",
            "100/100 - 29s - loss: 0.0191 - acc: 0.9919 - val_loss: 0.4963 - val_acc: 0.9595\n",
            "Epoch 20/100\n",
            "100/100 - 28s - loss: 0.0215 - acc: 0.9939 - val_loss: 0.8638 - val_acc: 0.9453\n",
            "Epoch 21/100\n",
            "100/100 - 29s - loss: 0.0221 - acc: 0.9944 - val_loss: 0.5498 - val_acc: 0.9605\n",
            "Epoch 22/100\n",
            "100/100 - 28s - loss: 0.0165 - acc: 0.9955 - val_loss: 1.0049 - val_acc: 0.9413\n",
            "Epoch 23/100\n",
            "100/100 - 28s - loss: 0.0154 - acc: 0.9954 - val_loss: 0.5862 - val_acc: 0.9615\n",
            "Epoch 24/100\n",
            "100/100 - 28s - loss: 0.0111 - acc: 0.9965 - val_loss: 1.1993 - val_acc: 0.9383\n",
            "Epoch 25/100\n",
            "100/100 - 29s - loss: 0.0143 - acc: 0.9954 - val_loss: 0.6419 - val_acc: 0.9575\n",
            "Epoch 26/100\n",
            "100/100 - 28s - loss: 0.0224 - acc: 0.9965 - val_loss: 0.2818 - val_acc: 0.9737\n",
            "Epoch 27/100\n",
            "100/100 - 27s - loss: 0.0242 - acc: 0.9939 - val_loss: 0.6170 - val_acc: 0.9555\n",
            "Epoch 28/100\n",
            "100/100 - 30s - loss: 0.0140 - acc: 0.9954 - val_loss: 0.4677 - val_acc: 0.9615\n",
            "Epoch 29/100\n",
            "100/100 - 29s - loss: 0.0146 - acc: 0.9959 - val_loss: 0.3981 - val_acc: 0.9605\n",
            "Epoch 30/100\n",
            "100/100 - 29s - loss: 0.0206 - acc: 0.9959 - val_loss: 0.7501 - val_acc: 0.9504\n",
            "Epoch 31/100\n",
            "100/100 - 28s - loss: 0.0229 - acc: 0.9934 - val_loss: 0.3992 - val_acc: 0.9676\n",
            "Epoch 32/100\n",
            "100/100 - 28s - loss: 0.0153 - acc: 0.9965 - val_loss: 0.4829 - val_acc: 0.9605\n",
            "Epoch 33/100\n",
            "100/100 - 28s - loss: 0.0164 - acc: 0.9955 - val_loss: 0.4613 - val_acc: 0.9605\n",
            "Epoch 34/100\n",
            "100/100 - 28s - loss: 0.0082 - acc: 0.9970 - val_loss: 0.4543 - val_acc: 0.9605\n",
            "Epoch 35/100\n",
            "100/100 - 29s - loss: 0.0267 - acc: 0.9944 - val_loss: 0.4447 - val_acc: 0.9615\n",
            "Epoch 36/100\n",
            "100/100 - 28s - loss: 0.0130 - acc: 0.9959 - val_loss: 0.4643 - val_acc: 0.9646\n",
            "Epoch 37/100\n",
            "100/100 - 28s - loss: 0.0087 - acc: 0.9950 - val_loss: 0.5016 - val_acc: 0.9686\n",
            "Epoch 38/100\n",
            "100/100 - 28s - loss: 0.0160 - acc: 0.9959 - val_loss: 0.5121 - val_acc: 0.9656\n",
            "Epoch 39/100\n",
            "100/100 - 28s - loss: 0.0117 - acc: 0.9965 - val_loss: 0.5108 - val_acc: 0.9636\n",
            "Epoch 40/100\n",
            "100/100 - 28s - loss: 0.0200 - acc: 0.9965 - val_loss: 0.4043 - val_acc: 0.9696\n",
            "Epoch 41/100\n",
            "100/100 - 29s - loss: 0.0158 - acc: 0.9949 - val_loss: 0.8403 - val_acc: 0.9545\n",
            "Epoch 42/100\n",
            "100/100 - 29s - loss: 0.0071 - acc: 0.9975 - val_loss: 0.6236 - val_acc: 0.9575\n",
            "Epoch 43/100\n",
            "100/100 - 29s - loss: 0.0261 - acc: 0.9940 - val_loss: 1.2963 - val_acc: 0.9403\n",
            "Epoch 44/100\n",
            "100/100 - 28s - loss: 0.0249 - acc: 0.9959 - val_loss: 0.9310 - val_acc: 0.9504\n",
            "Epoch 45/100\n",
            "100/100 - 28s - loss: 0.0180 - acc: 0.9959 - val_loss: 1.3436 - val_acc: 0.9443\n",
            "Epoch 46/100\n",
            "100/100 - 28s - loss: 0.0162 - acc: 0.9975 - val_loss: 1.3646 - val_acc: 0.9372\n",
            "Epoch 47/100\n",
            "100/100 - 28s - loss: 0.0138 - acc: 0.9960 - val_loss: 1.6133 - val_acc: 0.9291\n",
            "Epoch 48/100\n",
            "100/100 - 28s - loss: 0.0183 - acc: 0.9959 - val_loss: 1.0878 - val_acc: 0.9504\n",
            "Epoch 49/100\n",
            "100/100 - 28s - loss: 0.0138 - acc: 0.9964 - val_loss: 1.0271 - val_acc: 0.9605\n",
            "Epoch 50/100\n",
            "100/100 - 28s - loss: 0.0269 - acc: 0.9960 - val_loss: 1.4836 - val_acc: 0.9312\n",
            "Epoch 51/100\n",
            "100/100 - 28s - loss: 0.0110 - acc: 0.9975 - val_loss: 1.3430 - val_acc: 0.9443\n",
            "Epoch 52/100\n",
            "100/100 - 29s - loss: 0.0208 - acc: 0.9965 - val_loss: 1.9574 - val_acc: 0.9170\n",
            "Epoch 53/100\n",
            "100/100 - 27s - loss: 0.0138 - acc: 0.9975 - val_loss: 1.2250 - val_acc: 0.9433\n",
            "Epoch 54/100\n",
            "100/100 - 29s - loss: 0.0160 - acc: 0.9970 - val_loss: 1.8585 - val_acc: 0.9211\n",
            "Epoch 55/100\n",
            "100/100 - 29s - loss: 0.0053 - acc: 0.9985 - val_loss: 1.1503 - val_acc: 0.9474\n",
            "Epoch 56/100\n",
            "100/100 - 28s - loss: 0.0149 - acc: 0.9969 - val_loss: 1.6652 - val_acc: 0.9352\n",
            "Epoch 57/100\n",
            "100/100 - 28s - loss: 0.0075 - acc: 0.9990 - val_loss: 1.7234 - val_acc: 0.9291\n",
            "Epoch 58/100\n",
            "100/100 - 28s - loss: 0.0120 - acc: 0.9975 - val_loss: 1.7064 - val_acc: 0.9291\n",
            "Epoch 59/100\n",
            "100/100 - 28s - loss: 0.0088 - acc: 0.9969 - val_loss: 1.6990 - val_acc: 0.9322\n",
            "Epoch 60/100\n",
            "100/100 - 28s - loss: 0.0190 - acc: 0.9970 - val_loss: 1.1144 - val_acc: 0.9484\n",
            "Epoch 61/100\n",
            "100/100 - 28s - loss: 0.0188 - acc: 0.9954 - val_loss: 0.9715 - val_acc: 0.9534\n",
            "Epoch 62/100\n",
            "100/100 - 29s - loss: 0.0157 - acc: 0.9960 - val_loss: 1.8735 - val_acc: 0.9221\n",
            "Epoch 63/100\n",
            "100/100 - 28s - loss: 0.0128 - acc: 0.9980 - val_loss: 1.2923 - val_acc: 0.9403\n",
            "Epoch 64/100\n",
            "100/100 - 28s - loss: 0.0069 - acc: 0.9980 - val_loss: 1.8918 - val_acc: 0.9221\n",
            "Epoch 65/100\n",
            "100/100 - 28s - loss: 0.0200 - acc: 0.9965 - val_loss: 1.4583 - val_acc: 0.9413\n",
            "Epoch 66/100\n",
            "100/100 - 27s - loss: 0.0167 - acc: 0.9970 - val_loss: 1.3942 - val_acc: 0.9403\n",
            "Epoch 67/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 30s - loss: 0.0026 - acc: 0.9995 - val_loss: 1.4626 - val_acc: 0.9383\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "145d490f-61ce-4d3a-85d7-13a92fb5e5be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkVz6g6wPVVO",
        "colab_type": "code",
        "outputId": "8b54355e-3285-4489-fdc1-0a9f958d406f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150 , 150,3))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=20)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a human\")\n",
        "  else:\n",
        "    print(fn + \" is a horse\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-45d9530c-518d-4faf-957f-4e6c8776bd4f\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-45d9530c-518d-4faf-957f-4e6c8776bd4f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving white-horse-3010129_640.jpg to white-horse-3010129_640.jpg\n",
            "[1.]\n",
            "white-horse-3010129_640.jpg is a human\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
